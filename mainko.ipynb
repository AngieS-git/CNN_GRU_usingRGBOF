{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deque\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv2D, TimeDistributed, Flatten, GRU, Dropout, MaxPooling2D, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Numpy, Python, and TF seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_size = (224,224,3)\n",
    "seed_constant = 7\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)\n",
    "\n",
    "batch_size = 8 # Change this shit pag sasabog na yung GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 1/304"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 158\u001b[0m\n\u001b[1;32m    155\u001b[0m output_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/patrickpadua/Downloads/Yango RRL/CSV Generator/CNN_GRU_usingRGBOF/OF_test/LSB_1_Testing_combined_opencv_improved.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Process the video with optimized Lucas-Kanade\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m \u001b[43mprocess_video_with_optical_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 124\u001b[0m, in \u001b[0;36mprocess_video_with_optical_flow\u001b[0;34m(input_video_path, output_video_path, window_size, tau)\u001b[0m\n\u001b[1;32m    121\u001b[0m frame_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Calculate optical flow using optimized version\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m u, v \u001b[38;5;241m=\u001b[39m \u001b[43moptical_flow_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mold_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Create visualization\u001b[39;00m\n\u001b[1;32m    127\u001b[0m magnitude \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(u\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m v\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 77\u001b[0m, in \u001b[0;36moptical_flow_optimized\u001b[0;34m(I1g, I2g, window_size, tau)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(fx_windows\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(fx_windows\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m---> 77\u001b[0m         Ix \u001b[38;5;241m=\u001b[39m \u001b[43mfx_windows\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m         Iy \u001b[38;5;241m=\u001b[39m fy_windows[i, j]\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     79\u001b[0m         It \u001b[38;5;241m=\u001b[39m ft_windows[i, j]\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from numba import jit\n",
    "import numpy.lib.stride_tricks as stride_tricks\n",
    "\n",
    "@jit(nopython=True)\n",
    "def compute_flow_for_window(Ix, Iy, It, tau=0.01):\n",
    "    \"\"\"Compute flow for a single window using Numba acceleration.\"\"\"\n",
    "    # Build system of equations\n",
    "    n = len(Ix)\n",
    "    ATA = np.zeros((2, 2))\n",
    "    ATb = np.zeros(2)\n",
    "    \n",
    "    # Manually compute A^T * A and A^T * b\n",
    "    for i in range(n):\n",
    "        ATA[0, 0] += Ix[i] * Ix[i]\n",
    "        ATA[0, 1] += Ix[i] * Iy[i]\n",
    "        ATA[1, 0] += Ix[i] * Iy[i]\n",
    "        ATA[1, 1] += Iy[i] * Iy[i]\n",
    "        ATb[0] += -Ix[i] * It[i]\n",
    "        ATb[1] += -Iy[i] * It[i]\n",
    "    \n",
    "    # Check eigenvalues using determinant and trace\n",
    "    det = ATA[0, 0] * ATA[1, 1] - ATA[0, 1] * ATA[1, 0]\n",
    "    trace = ATA[0, 0] + ATA[1, 1]\n",
    "    \n",
    "    if det > tau and trace > tau:\n",
    "        # Solve 2x2 system manually\n",
    "        inv_det = 1.0 / det\n",
    "        u = (ATA[1, 1] * ATb[0] - ATA[0, 1] * ATb[1]) * inv_det\n",
    "        v = (-ATA[1, 0] * ATb[0] + ATA[0, 0] * ATb[1]) * inv_det\n",
    "        return u, v\n",
    "    return 0.0, 0.0\n",
    "\n",
    "def sliding_window_view(arr, window_shape):\n",
    "    \"\"\"Create a sliding window view of an array.\"\"\"\n",
    "    shape = np.array(arr.shape)\n",
    "    window_shape = np.array(window_shape)\n",
    "    \n",
    "    slices = tuple(slice(None, None, None) for _ in range(len(window_shape)))\n",
    "    window_strides = np.array(arr.strides)\n",
    "    \n",
    "    indexing_strides = arr.strides\n",
    "    win_indices = np.array(window_shape).reshape(-1, 1)\n",
    "    new_shape = tuple(shape - window_shape + 1) + tuple(window_shape)\n",
    "    new_strides = tuple(indexing_strides) + tuple(window_strides)\n",
    "    \n",
    "    return stride_tricks.as_strided(arr, new_shape, new_strides)\n",
    "\n",
    "def optical_flow_optimized(I1g, I2g, window_size, tau=0.01):\n",
    "    \"\"\"\n",
    "    Optimized implementation of Lucas-Kanade optical flow.\n",
    "    \"\"\"\n",
    "    # Normalize and convert to float32 for better performance\n",
    "    I1g = (I1g / 255.).astype(np.float32)\n",
    "    I2g = (I2g / 255.).astype(np.float32)\n",
    "    \n",
    "    # Compute derivatives using Sobel for better accuracy and speed\n",
    "    fx = cv2.Sobel(I1g, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    fy = cv2.Sobel(I1g, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    ft = I2g - I1g\n",
    "    \n",
    "    # Initialize motion components\n",
    "    u = np.zeros(I1g.shape, dtype=np.float32)\n",
    "    v = np.zeros(I1g.shape, dtype=np.float32)\n",
    "    \n",
    "    # Create sliding windows\n",
    "    w = window_size // 2\n",
    "    fx_windows = sliding_window_view(fx, (window_size, window_size))\n",
    "    fy_windows = sliding_window_view(fy, (window_size, window_size))\n",
    "    ft_windows = sliding_window_view(ft, (window_size, window_size))\n",
    "    \n",
    "    # Process each window\n",
    "    for i in range(fx_windows.shape[0]):\n",
    "        for j in range(fx_windows.shape[1]):\n",
    "            Ix = fx_windows[i, j].flatten()\n",
    "            Iy = fy_windows[i, j].flatten()\n",
    "            It = ft_windows[i, j].flatten()\n",
    "            \n",
    "            flow = compute_flow_for_window(Ix, Iy, It, tau)\n",
    "            u[i+w, j+w] = flow[0]\n",
    "            v[i+w, j+w] = flow[1]\n",
    "    \n",
    "    return u, v\n",
    "\n",
    "def process_video_with_optical_flow(input_video_path, output_video_path, window_size=15, tau=0.01):\n",
    "    \"\"\"\n",
    "    Process video with optimized Lucas-Kanade optical flow and create visualization.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open {input_video_path}\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Create video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # Read first frame\n",
    "    ret, old_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read first frame\")\n",
    "        return\n",
    "\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    frame_num = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_num += 1\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate optical flow using optimized version\n",
    "        u, v = optical_flow_optimized(old_gray, frame_gray, window_size, tau)\n",
    "\n",
    "        # Create visualization\n",
    "        magnitude = np.sqrt(u**2 + v**2)\n",
    "        magnitude_normalized = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "        # Create color visualization using HSV\n",
    "        hsv = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "        hsv[..., 0] = cv2.normalize(np.arctan2(v, u) * 180 / np.pi, None, 0, 180, cv2.NORM_MINMAX)\n",
    "        hsv[..., 1] = 255\n",
    "        hsv[..., 2] = magnitude_normalized\n",
    "\n",
    "        # Convert HSV to BGR for visualization\n",
    "        flow_rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "        # Write frame\n",
    "        out.write(flow_rgb)\n",
    "\n",
    "        # Update for next frame\n",
    "        old_gray = frame_gray.copy()\n",
    "\n",
    "        # Progress update\n",
    "        print(f\"\\rProcessing frame {frame_num}/{total_frames}\", end=\"\")\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"\\nOptical flow video saved to {output_video_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Your specific video paths\n",
    "    input_video_path = \"/Users/patrickpadua/Downloads/Yango RRL/CSV Generator/CNN_GRU_usingRGBOF/RawDataset/Testing/LumbarSideBends/LSB_1_Testing.mp4\"\n",
    "    output_video_path = \"/Users/patrickpadua/Downloads/Yango RRL/CSV Generator/CNN_GRU_usingRGBOF/OF_test/LSB_1_Testing_combined_opencv_improved.mp4\"\n",
    "\n",
    "    # Process the video with optimized Lucas-Kanade\n",
    "    process_video_with_optical_flow(input_video_path, output_video_path, window_size=15, tau=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/video/src/lkpyramid.cpp:1274: error: (-215:Assertion failed) nextPtsMat.checkVector(2, CV_32F, true) == npoints in function 'calc'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 150\u001b[0m\n\u001b[1;32m    148\u001b[0m input_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/patrickpadua/Downloads/Yango RRL/CSV Generator/CNN_GRU_usingRGBOF/RawDataset/Testing/LumbarSideBends/LSB_1_Testing.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m output_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/patrickpadua/Downloads/Yango RRL/CSV Generator/CNN_GRU_usingRGBOF/OF_test/LSB_1_Testing_combined_opencv_improved.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 150\u001b[0m \u001b[43mprocess_video_with_fast_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 74\u001b[0m, in \u001b[0;36mprocess_video_with_fast_flow\u001b[0;34m(input_video_path, output_video_path)\u001b[0m\n\u001b[1;32m     71\u001b[0m     p0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel()))\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Calculate optical flow with pyramid\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m p1, st, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalcOpticalFlowPyrLK\u001b[49m\u001b[43m(\u001b[49m\u001b[43mold_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlk_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Vectorized flow field calculation\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m st \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/video/src/lkpyramid.cpp:1274: error: (-215:Assertion failed) nextPtsMat.checkVector(2, CV_32F, true) == npoints in function 'calc'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def process_video_with_fast_flow(input_video_path, output_video_path):\n",
    "    \"\"\"\n",
    "    Optimized version with faster processing using:\n",
    "    - Sparse feature points\n",
    "    - Vectorized operations\n",
    "    - Reduced computational complexity\n",
    "    - Hardware acceleration (if available)\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open {input_video_path}\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Create video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # Read first frame\n",
    "    ret, old_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read first frame\")\n",
    "        return\n",
    "\n",
    "    # Preprocessing optimized with Gaussian blur instead of bilateral\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "    old_gray = cv2.GaussianBlur(old_gray, (5, 5), 0)\n",
    "\n",
    "    # Create sparse grid (reduced density)\n",
    "    grid_step = 20\n",
    "    y, x = np.mgrid[grid_step//2:height:grid_step, grid_step//2:width:grid_step]\n",
    "    p0 = np.vstack((x.ravel(), y.ravel())).T.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    # Optimized LK parameters\n",
    "    lk_params = dict(\n",
    "        winSize=(15, 15),        # Balanced window size\n",
    "        maxLevel=3,              # Increased pyramid levels\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 7, 0.03),\n",
    "        flags=cv2.OPTFLOW_USE_INITIAL_FLOW,\n",
    "        minEigThreshold=1e-4\n",
    "    )\n",
    "\n",
    "    # Preallocate arrays for flow visualization\n",
    "    hsv = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    hsv[..., 1] = 255  # Saturation is always maximum\n",
    "\n",
    "    frame_num = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_num += 1\n",
    "        \n",
    "        # Optimized preprocessing\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame_gray = cv2.GaussianBlur(frame_gray, (5, 5), 0)\n",
    "\n",
    "        # Check if p0 is empty or invalid\n",
    "        if p0 is None or p0.shape[0] == 0:\n",
    "            # Reinitialize p0 if it's empty\n",
    "            y, x = np.mgrid[grid_step//2:height:grid_step, grid_step//2:width:grid_step]\n",
    "            p0 = np.vstack((x.ravel(), y.ravel())).T.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "        # Calculate optical flow with pyramid\n",
    "        p1, st, _ = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "        # Vectorized flow field calculation\n",
    "        if p1 is not None and st is not None:\n",
    "            good_new = p1[st == 1]\n",
    "            good_old = p0[st == 1]\n",
    "            \n",
    "            # Calculate flow vectors in vectorized manner\n",
    "            flow_vectors = good_new - good_old\n",
    "            x_old = good_old[:, 0, 0].astype(int)\n",
    "            y_old = good_old[:, 0, 1].astype(int)\n",
    "            \n",
    "            # Create mask for valid coordinates\n",
    "            valid = (x_old >= 0) & (x_old < width) & (y_old >= 0) & (y_old < height)\n",
    "            x_old = x_old[valid]\n",
    "            y_old = y_old[valid]\n",
    "            flow_vectors = flow_vectors[valid]\n",
    "\n",
    "            # Create sparse flow field\n",
    "            u_sparse = np.zeros_like(old_gray, dtype=np.float32)\n",
    "            v_sparse = np.zeros_like(old_gray, dtype=np.float32)\n",
    "            u_sparse[y_old, x_old] = flow_vectors[:, 0, 0]\n",
    "            v_sparse[y_old, x_old] = flow_vectors[:, 0, 1]\n",
    "\n",
    "            # Fast Gaussian blur with smaller kernel\n",
    "            u = cv2.GaussianBlur(u_sparse, (3, 3), 0)\n",
    "            v = cv2.GaussianBlur(v_sparse, (3, 3), 0)\n",
    "        else:\n",
    "            u = np.zeros_like(old_gray, dtype=np.float32)\n",
    "            v = np.zeros_like(old_gray, dtype=np.float32)\n",
    "\n",
    "        # Create HSV visualization\n",
    "        magnitude, angle = cv2.cartToPolar(u, v, angleInDegrees=True)\n",
    "        hsv[..., 0] = (angle / 2).astype(np.uint8)  # Hue range is 0-180 for OpenCV\n",
    "        hsv[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        flow_rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "        # Sparse vector visualization (every 5th frame)\n",
    "        if frame_num % 5 == 0 and p1 is not None:\n",
    "            mask = magnitude[y_old, x_old] > np.median(magnitude[y_old, x_old])\n",
    "            for x_p, y_p, dx, dy in zip(x_old[mask], y_old[mask], \n",
    "                                      flow_vectors[mask, 0, 0], \n",
    "                                      flow_vectors[mask, 0, 1]):\n",
    "                cv2.arrowedLine(flow_rgb, \n",
    "                              (x_p, y_p),\n",
    "                              (int(x_p + dx*3), int(y_p + dy*3)),\n",
    "                              (0, 255, 0), 1, tipLength=0.2)\n",
    "\n",
    "        # Write frame\n",
    "        out.write(flow_rgb)\n",
    "\n",
    "        # Update for next frame\n",
    "        old_gray = frame_gray.copy()\n",
    "        if p1 is not None and st is not None:\n",
    "            p0 = good_new.reshape(-1, 1, 2)\n",
    "        else:\n",
    "            # Reinitialize p0 if tracking failed\n",
    "            y, x = np.mgrid[grid_step//2:height:grid_step, grid_step//2:width:grid_step]\n",
    "            p0 = np.vstack((x.ravel(), y.ravel())).T.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "        # Maintain point density by reinitializing periodically\n",
    "        if frame_num % 30 == 0:\n",
    "            y, x = np.mgrid[grid_step//2:height:grid_step*2, grid_step//2:width:grid_step*2]\n",
    "            new_points = np.vstack((x.ravel(), y.ravel())).T.reshape(-1, 1, 2).astype(np.float32)\n",
    "            p0 = np.vstack((p0, new_points))\n",
    "            p0 = p0[:len(x.ravel())]  # Maintain original point count\n",
    "\n",
    "        print(f\"\\rProcessed frame {frame_num}/{total_frames}\", end=\"\")\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"\\nOptimized optical flow video saved to {output_video_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_video_path = \"/Users/patrickpadua/Downloads/Yango RRL/CSV Generator/CNN_GRU_usingRGBOF/RawDataset/Testing/LumbarSideBends/LSB_1_Testing.mp4\"\n",
    "    output_video_path = \"/Users/patrickpadua/Downloads/Yango RRL/CSV Generator/CNN_GRU_usingRGBOF/OF_test/LSB_1_Testing_combined_opencv_improved.mp4\"\n",
    "    process_video_with_fast_flow(input_video_path, output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    input_video_path = \"/Users/patrickpadua/Downloads/Yango RRL/CSV Generator/CNN_GRU_usingRGBOF/RawDataset/Testing/LumbarSideBends/LSB_1_Testing.mp4\"\n",
    "    output_video_path = \"/Users/patrickpadua/Downloads/Yango RRL/CSV Generator/CNN_GRU_usingRGBOF/OF_test/LSB_1_Testing_combined_opencv_improved.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PreProcess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT, IMAGE_WIDTH =  64, 64\n",
    "\n",
    "SEQUENCE_LENGTH = 20\n",
    "\n",
    "DATASET_DIR = r\"D:\\MAPUA\\CNN-GRU_exp\\UCF50\"\n",
    "\n",
    "CLASSES_LIST = [\"BenchPress\", \"CleanAndJerk\", \"JumpingJack\", \"Lunges\", \"PushUps\", \"Taichi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "def dense_optical_flow(method, video_path, params=[], to_gray=False):\n",
    "    # read the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # Read the first frame\n",
    "    ret, old_frame = cap.read()\n",
    "\n",
    "    # crate HSV & make Value a constant\n",
    "    hsv = np.zeros_like(old_frame)\n",
    "    hsv[..., 1] = 255\n",
    "\n",
    "    # Preprocessing for exact method\n",
    "    if to_gray:\n",
    "        old_frame = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    while True:\n",
    "        # Read the next frame\n",
    "        ret, new_frame = cap.read()\n",
    "        frame_copy = new_frame\n",
    "        if not ret:\n",
    "            break\n",
    "        # Preprocessing for exact method\n",
    "        if to_gray:\n",
    "            new_frame = cv2.cvtColor(new_frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Calculate Optical Flow\n",
    "        flow = method(old_frame, new_frame, None, *params)\n",
    "\n",
    "        # Encoding: convert the algorithm's output into Polar coordinates\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        # Use Hue and Saturation to encode the Optical Flow\n",
    "        hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "        hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        # Convert HSV image into BGR for demo\n",
    "        bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        cv2.imshow(\"frame\", frame_copy)\n",
    "        cv2.imshow(\"optical flow\", bgr)\n",
    "        k = cv2.waitKey(25) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "        old_frame = new_frame\n",
    "\n",
    "def lucas_kanade_method(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # params for ShiTomasi corner detection\n",
    "    feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params = dict(\n",
    "        winSize=(15, 15),\n",
    "        maxLevel=2,\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
    "    )\n",
    "    # Create some random colors\n",
    "    color = np.random.randint(0, 255, (100, 3))\n",
    "    # Take first frame and find corners in it\n",
    "    ret, old_frame = cap.read()\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "    # Create a mask image for drawing purposes\n",
    "    mask = np.zeros_like(old_frame)\n",
    "    while True: \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # calculate optical flow\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "            old_gray, frame_gray, p0, None, **lk_params\n",
    "        )\n",
    "        # Select good points\n",
    "        good_new = p1[st == 1]\n",
    "        good_old = p0[st == 1]\n",
    "        # draw the tracks\n",
    "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            mask = cv2.line(mask, (a, b), (c, d), color[i].tolist(), 2)\n",
    "            frame = cv2.circle(frame, (a, b), 5, color[i].tolist(), -1)\n",
    "        img = cv2.add(frame, mask)\n",
    "        cv2.imshow(\"frame\", img)\n",
    "        k = cv2.waitKey(25) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "        if k == ord(\"c\"):\n",
    "            mask = np.zeros_like(old_frame)\n",
    "        # Now update the previous frame and previous points\n",
    "        old_gray = frame_gray.copy()\n",
    "        p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "def main():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--algorithm\",\n",
    "        choices=[\"farneback\", \"lucaskanade\", \"lucaskanade_dense\", \"rlof\"],\n",
    "        required=True,\n",
    "        help=\"Optical flow algorithm to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--video_path\", default=\"videos/cat.mp4\", help=\"Path to the video\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    video_path = args.video_path\n",
    "    if args.algorithm == \"lucaskanade\":\n",
    "        lucas_kanade_method(video_path)\n",
    "    elif args.algorithm == \"lucaskanade_dense\":\n",
    "        method = cv2.optflow.calcOpticalFlowSparseToDense\n",
    "        dense_optical_flow(method, video_path, to_gray=True)\n",
    "    elif args.algorithm == \"farneback\":\n",
    "        method = cv2.calcOpticalFlowFarneback\n",
    "        params = [0.5, 3, 15, 3, 5, 1.2, 0]  # Farneback's algorithm parameters\n",
    "        dense_optical_flow(method, video_path, params, to_gray=True)\n",
    "    elif args.algorithm == \"rlof\":\n",
    "        method = cv2.optflow.calcOpticalFlowDenseRLOF\n",
    "        dense_optical_flow(method, video_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
